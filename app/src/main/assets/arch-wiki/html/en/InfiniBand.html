<!DOCTYPE html>
<html lang="en" dir="ltr" class="client-nojs">
<head>
<meta charset="UTF-8">
<title>InfiniBand - ArchWiki</title>
<link rel="stylesheet" href="../ArchWikiOffline.css">
<meta name="ResourceLoaderDynamicStyles" content="">
<style></style>
<meta name="generator" content="MediaWiki 1.26.4">
<meta name="robots" content="noindex,follow">
<link rel="shortcut icon" href="/favicon.ico">
<link rel="search" type="application/opensearchdescription+xml" href="/opensearch_desc.php" title="ArchWiki (en)">
<link rel="EditURI" type="application/rsd+xml" href="https://wiki.archlinux.org/api.php?action=rsd">
<link rel="copyright" href="http://www.gnu.org/copyleft/fdl.html">
<link rel="alternate" type="application/atom+xml" title="ArchWiki Atom feed" href="/index.php?title=Special:RecentChanges&amp;feed=atom">
</head>
<body class="mediawiki ltr sitedir-ltr ns-0 ns-subject page-InfiniBand skin-archlinux action-view">

		<div id="globalWrapper" style="width: 100%">
		<div id="column-content">
			<div id="content" class="mw-body" role="main" style="margin: 0.5em; margin-bottom:0; margin-top:0">
				<a id="top"></a>
				
				<div class="mw-indicators">
</div>
				<h1 id="firstHeading" class="firstHeading" lang="en">InfiniBand</h1>
				
				<div id="bodyContent" class="mw-body-content">
					<div id="contentSub"></div>
										<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr">
<div class="noprint archwiki-template-message">
<p><a href="../File:Tango-edit-clear.png" class="image"><img alt="Tango-edit-clear.png" src="../File:Tango-edit-clear.png" width="48" height="48"></a><b>This article or section needs language, wiki syntax or style improvements.</b><a href="../File:Tango-edit-clear.png" class="image"><img alt="Tango-edit-clear.png" src="../File:Tango-edit-clear.png" width="48" height="48"></a></p>
<div>
<b>Reason:</b> Numerous <a href="../en/Help:Style.html" title="Help:Style">Help:Style</a> violations. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/index.php/Talk:InfiniBand">Talk:InfiniBand#</a>)</div>
</div>
<p>This page explains how to set up, diagnose, and benchmark an InfiniBand network.
</p>
<div id="toc" class="toc">
<div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1">
<a href="#Introduction"><span class="tocnumber">1</span> <span class="toctext">Introduction</span></a>
<ul>
<li class="toclevel-2 tocsection-2"><a href="#Overview"><span class="tocnumber">1.1</span> <span class="toctext">Overview</span></a></li>
<li class="toclevel-2 tocsection-3"><a href="#Affordable_used_equipment"><span class="tocnumber">1.2</span> <span class="toctext">Affordable used equipment</span></a></li>
<li class="toclevel-2 tocsection-4">
<a href="#Bandwidth"><span class="tocnumber">1.3</span> <span class="toctext">Bandwidth</span></a>
<ul>
<li class="toclevel-3 tocsection-5"><a href="#Signal_transfer_rates"><span class="tocnumber">1.3.1</span> <span class="toctext">Signal transfer rates</span></a></li>
<li class="toclevel-3 tocsection-6"><a href="#Effective_throughput_.26_multiple_virtual_lanes"><span class="tocnumber">1.3.2</span> <span class="toctext">Effective throughput &amp; multiple virtual lanes</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-7"><a href="#Latency"><span class="tocnumber">1.4</span> <span class="toctext">Latency</span></a></li>
<li class="toclevel-2 tocsection-8"><a href="#Backwards_compatibility"><span class="tocnumber">1.5</span> <span class="toctext">Backwards compatibility</span></a></li>
<li class="toclevel-2 tocsection-9"><a href="#Cables"><span class="tocnumber">1.6</span> <span class="toctext">Cables</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-10">
<a href="#Terminology"><span class="tocnumber">2</span> <span class="toctext">Terminology</span></a>
<ul>
<li class="toclevel-2 tocsection-11"><a href="#Hardware"><span class="tocnumber">2.1</span> <span class="toctext">Hardware</span></a></li>
<li class="toclevel-2 tocsection-12"><a href="#GUID"><span class="tocnumber">2.2</span> <span class="toctext">GUID</span></a></li>
<li class="toclevel-2 tocsection-13"><a href="#NEED_ANOTHER_NAME"><span class="tocnumber">2.3</span> <span class="toctext">NEED ANOTHER NAME</span></a></li>
<li class="toclevel-2 tocsection-14"><a href="#Software"><span class="tocnumber">2.4</span> <span class="toctext">Software</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-15">
<a href="#Software_installation"><span class="tocnumber">3</span> <span class="toctext">Software installation</span></a>
<ul>
<li class="toclevel-2 tocsection-16">
<a href="#Upgrade_firmware"><span class="tocnumber">3.1</span> <span class="toctext">Upgrade firmware</span></a>
<ul>
<li class="toclevel-3 tocsection-17"><a href="#For_Mellanox"><span class="tocnumber">3.1.1</span> <span class="toctext">For Mellanox</span></a></li>
<li class="toclevel-3 tocsection-18"><a href="#For_Intel.2FQLogic"><span class="tocnumber">3.1.2</span> <span class="toctext">For Intel/QLogic</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-19"><a href="#Kernel_modules"><span class="tocnumber">3.2</span> <span class="toctext">Kernel modules</span></a></li>
<li class="toclevel-2 tocsection-20">
<a href="#Subnet_manager"><span class="tocnumber">3.3</span> <span class="toctext">Subnet manager</span></a>
<ul>
<li class="toclevel-3 tocsection-21"><a href="#For_a_software_subnet_manager.2C_use_opensm"><span class="tocnumber">3.3.1</span> <span class="toctext">For a software subnet manager, use opensm</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-22">
<a href="#TCP.2FIP_over_InfiniBand_.28IPoIB.29"><span class="tocnumber">3.4</span> <span class="toctext">TCP/IP over InfiniBand (IPoIB)</span></a>
<ul>
<li class="toclevel-3 tocsection-23"><a href="#Connection_mode"><span class="tocnumber">3.4.1</span> <span class="toctext">Connection mode</span></a></li>
<li class="toclevel-3 tocsection-24"><a href="#MTU"><span class="tocnumber">3.4.2</span> <span class="toctext">MTU</span></a></li>
<li class="toclevel-3 tocsection-25"><a href="#Fine-tuning_connection_mode_and_MTU"><span class="tocnumber">3.4.3</span> <span class="toctext">Fine-tuning connection mode and MTU</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-26">
<a href="#Remote_Data_Storage_over_InfiniBand"><span class="tocnumber">3.5</span> <span class="toctext">Remote Data Storage over InfiniBand</span></a>
<ul>
<li class="toclevel-3 tocsection-27">
<a href="#targetcli"><span class="tocnumber">3.5.1</span> <span class="toctext">targetcli</span></a>
<ul>
<li class="toclevel-4 tocsection-28"><a href="#Installing_and_using"><span class="tocnumber">3.5.1.1</span> <span class="toctext">Installing and using</span></a></li>
<li class="toclevel-4 tocsection-29"><a href="#Create_backstores"><span class="tocnumber">3.5.1.2</span> <span class="toctext">Create backstores</span></a></li>
</ul>
</li>
<li class="toclevel-3 tocsection-30">
<a href="#iSCSI"><span class="tocnumber">3.5.2</span> <span class="toctext">iSCSI</span></a>
<ul>
<li class="toclevel-4 tocsection-31"><a href="#Over_IPoIB"><span class="tocnumber">3.5.2.1</span> <span class="toctext">Over IPoIB</span></a></li>
<li class="toclevel-4 tocsection-32">
<a href="#Over_iSER"><span class="tocnumber">3.5.2.2</span> <span class="toctext">Over iSER</span></a>
<ul>
<li class="toclevel-5 tocsection-33"><a href="#Bug_with_multiple_iSER_devices.2C_workarounds"><span class="tocnumber">3.5.2.2.1</span> <span class="toctext">Bug with multiple iSER devices, workarounds</span></a></li>
<li class="toclevel-5 tocsection-34"><a href="#Configuring_iSER_devices"><span class="tocnumber">3.5.2.2.2</span> <span class="toctext">Configuring iSER devices</span></a></li>
<li class="toclevel-5 tocsection-35"><a href="#Workaround_for_multiple_iSER_devices_on_open-iscsi_2.0_873-7"><span class="tocnumber">3.5.2.2.3</span> <span class="toctext">Workaround for multiple iSER devices on open-iscsi 2.0_873-7</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-3 tocsection-36"><a href="#SRP"><span class="tocnumber">3.5.3</span> <span class="toctext">SRP</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-37">
<a href="#InfiniBand_programs_for_diagnosing_and_benchmarking"><span class="tocnumber">4</span> <span class="toctext">InfiniBand programs for diagnosing and benchmarking</span></a>
<ul>
<li class="toclevel-2 tocsection-38"><a href="#ibstat_-_View_a_computer.27s_InfiniBand_GUIDs"><span class="tocnumber">4.1</span> <span class="toctext">ibstat - View a computer's InfiniBand GUIDs</span></a></li>
<li class="toclevel-2 tocsection-39"><a href="#ibhosts_-_View_all_hosts_on_InfiniBand_network"><span class="tocnumber">4.2</span> <span class="toctext">ibhosts - View all hosts on InfiniBand network</span></a></li>
<li class="toclevel-2 tocsection-40"><a href="#ibswitches_-_View_all_switches_on_InfiniBand_network"><span class="tocnumber">4.3</span> <span class="toctext">ibswitches - View all switches on InfiniBand network</span></a></li>
<li class="toclevel-2 tocsection-41"><a href="#iblinkinfo_-_View_link_information_on_InfiniBand_network"><span class="tocnumber">4.4</span> <span class="toctext">iblinkinfo - View link information on InfiniBand network</span></a></li>
<li class="toclevel-2 tocsection-42"><a href="#ibping_-_Ping_another_InfiniBand_device"><span class="tocnumber">4.5</span> <span class="toctext">ibping - Ping another InfiniBand device</span></a></li>
<li class="toclevel-2 tocsection-43"><a href="#ibdiagnet_-_Show_diagnostic_information_for_entire_subnet"><span class="tocnumber">4.6</span> <span class="toctext">ibdiagnet - Show diagnostic information for entire subnet</span></a></li>
<li class="toclevel-2 tocsection-44">
<a href="#qperf_-_Measure_performance_over_RDMA_or_TCP.2FIP"><span class="tocnumber">4.7</span> <span class="toctext">qperf - Measure performance over RDMA or TCP/IP</span></a>
<ul>
<li class="toclevel-3 tocsection-45"><a href="#TCP.2FIP_over_IPoIB"><span class="tocnumber">4.7.1</span> <span class="toctext">TCP/IP over IPoIB</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-46"><a href="#iperf_-_Measure_performance_over_TCP.2FIP"><span class="tocnumber">4.8</span> <span class="toctext">iperf - Measure performance over TCP/IP</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-47">
<a href="#Common_problems_.2F_FAQ"><span class="tocnumber">5</span> <span class="toctext">Common problems / FAQ</span></a>
<ul>
<li class="toclevel-2 tocsection-48">
<a href="#Connection_problems"><span class="tocnumber">5.1</span> <span class="toctext">Connection problems</span></a>
<ul>
<li class="toclevel-3 tocsection-49"><a href="#Link.2C_physical_state.2C_and_port_state"><span class="tocnumber">5.1.1</span> <span class="toctext">Link, physical state, and port state</span></a></li>
<li class="toclevel-3 tocsection-50"><a href="#getaddrinfo_failed:_Name_or_service_not_known"><span class="tocnumber">5.1.2</span> <span class="toctext">getaddrinfo failed: Name or service not known</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-51"><a href="#Speed_problems"><span class="tocnumber">5.2</span> <span class="toctext">Speed problems</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-52"><a href="#Network_segmentation"><span class="tocnumber">6</span> <span class="toctext">Network segmentation</span></a></li>
<li class="toclevel-1 tocsection-53"><a href="#How_can_I_use_libsdp_for_SDP_.28Sockets_Direct_Protocol.29.3F_.3D"><span class="tocnumber">7</span> <span class="toctext">How can I use libsdp for SDP (Sockets Direct Protocol)? =</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Introduction">Introduction</span></h2>
<h3><span class="mw-headline" id="Overview">Overview</span></h3>
<p>InfiniBand (abbreviated IB) is an alternative to Ethernet and Fibre Channel.  InfiniBand provides high bandwidth and low latency.  InfiniBand can transfer data directly to and from a storage device on one machine to userspace on another machine, bypassing and avoiding the overhead of a system call.  InfiniBand adapters can handle the networking protocols, unlike Ethernet networking protocols which are ran on the CPU.  This allows the OS's and CPU's to remain free while the high bandwidth transfers take place, which can be a real problem with 10Gb+ Ethernet.
</p>
<p>InfiniBand hardware is made by Mellanox (which merged with Voltaire, and is heavily backed by Oracle) and Intel (which acquired QLogic's InfiniBand program.)  InfiniBand is most often used by supercomputers, clusters, and data centers.  IBM, HP, and Cray are also members of the InfiniBand Steering Committee.  Facebook, Twitter, eBay, YouTube, and PayPal are examples of InfiniBand users.
</p>
<p>InfiniBand software is developed under the <a rel="nofollow" class="external text" href="http://www.openfabrics.org">OpenFabrics Open Source Alliance</a>
</p>
<h3><span class="mw-headline" id="Affordable_used_equipment">Affordable used equipment</span></h3>
<p>With large businesses benefiting so much from jumping to newer versions, the maximum length limitations of passive InfiniBand cabling, the high cost of active InfiniBand cabling, and the more technically complex setup than Ethernet, the used InfiniBand market is heavily saturated, allowing used InfiniBand devices to affordably be used at home or smaller businesses for their internal networks.
</p>
<h3><span class="mw-headline" id="Bandwidth">Bandwidth</span></h3>
<h4><span class="mw-headline" id="Signal_transfer_rates">Signal transfer rates</span></h4>
<p>InfiniBand transfer rates now correspond to the maximum supported by PCI Express (abbreviated PCIe).  It originally corresponded to PCI Extended (abbreviated PCI-X), which severely limited performance.  It launched using SDR (Single Data Rate) with a signaling rate of 2.5Gb/s per lane (corresponding with PCI Express v1.0), and has added: DDR (Double Data Rate) at 5Gb/s (PCI Express v2.0); QDR (Quad Data Rate) at 10Gb/s (PCI Express 3.0); and FDR (Fourteen Data Rate) at 14.0625Gbps (PCI Express 4.0.)  InfiniBand is now delivering EDR (Enhanced Data Rate) at 25Gb/s.  Planned around 2017 will be HDR (High Data Rate) at 50Gb/s.
</p>
<h4><span class="mw-headline" id="Effective_throughput_.26_multiple_virtual_lanes">Effective throughput &amp; multiple virtual lanes</span></h4>
<p>Because SDR, DDR, and QDR versions use 8/10 encoding (8 bits of data takes 10 bits of signaling), effective throughput for these is lowered to 80%: SDR at 2Gb/s/lane; DDR at 4Gb/s/lane; and QDR at 8Gb/s/lane.  Starting with FDR, InfiniBand uses 64/66 encoding, allowing a higher effective throughput to signaling rate ratio of 96.97%: FDR at 13.64Gb/s/lane; EDR at 24.24Gb/s/lane; and HDR at 48.48Gb/s/lane.
</p>
<p>InfiniBand devices are capable of using multiple virtual lanes, most using 4X, but some using a slower 1X or faster 12X.
</p>
<p>When using the common 4X lane devices, this effectively allows total effective throughputs of: SDR of 8Gb/s; DDR of 16Gb/s; QDR of 32Gb/s; FDR of 54.54Gb/s; EDR of 96.97Gb/s; and HDR of 193.94Gb/s.
</p>
<h3><span class="mw-headline" id="Latency">Latency</span></h3>
<p>InfiniBand's latency is incredibly small: SDR (5us); DDR (2.5us); QDR (1.3us); FDR (0.7us); EDR (0.5us); and HDR (&lt; 0.5us.)  For comparison 10Gb Ethernet is more like 7.22us, ten times more than FDR's latency.
</p>
<h3><span class="mw-headline" id="Backwards_compatibility">Backwards compatibility</span></h3>
<p>InfiniBand devices are almost always backwards compatible.  Connections should be established at the lowest common denominator.  A DDR adapter meant for a PCI Express 8x slot should work in a PCI Express 4x slot.  (With half the bandwidth.)
</p>
<h3><span class="mw-headline" id="Cables">Cables</span></h3>
<p>InfiniBand passive copper cables can be up to 7 meters using up to QDR, and 3 meters using FDR.
</p>
<p>InfiniBand active fiber (optical) cables can be up to 300 meters using up to FDR.  (Only 100 meters on FDR10, which is a variant not otherwise really discussed in this article.)
</p>
<p>Mellanox MetroX devices exist which allow up to 80 kilometer (50 mile) connections.  Latency increases by about 5us per kilometer.
</p>
<p>An InfiniBand cable can be used to directly link two computers without a switch; InfiniBand cross-over cables do not exist.
</p>
<h2><span class="mw-headline" id="Terminology">Terminology</span></h2>
<h3><span class="mw-headline" id="Hardware">Hardware</span></h3>
<p>Adapters, switches, routers, and bridges/gateways must be specifically made for InfiniBand.
</p>
<dl>
<dt> HCA (Host Channel Adapter)</dt>
<dd> Like an Ethernet NIC (Network Interface Card).  Connects the InfiniBand cable to the PCI Express bus, at the full speed of the bus if the proper generation of HCA is used.  An end node on an InfiniBand network, executes transport-level functions, and supports the InfiniBand verbs interface.</dd>
<dt> Switch</dt>
<dd> Like an Ethernet NIC.  Moves packets from one link to another on the same InfiniBand subnet.</dd>
<dt> Router</dt>
<dd> Like an Ethernet router.  Moves packets between different InfiniBand subnets.</dd>
<dt> Bridge/Gateway</dt>
<dd> A standalone piece of hardware, or a computer performing this function.  Bridges InfiniBand and Ethernet networks.</dd>
</dl>
<h3><span class="mw-headline" id="GUID">GUID</span></h3>
<p>Like Ethernet MAC addresses, but a device has multiple GUID's.  Assigned by the hardware manufacturer, and remains the same through reboots.  64-bit addresses (24-bit manufacturer prefix and 40-bit device identifier.)  Given to adapters, switches, routers, and bridges/gateways.
</p>
<dl>
<dt> Node GUID</dt>
<dd> Identifies the HCA, Switch, or Router</dd>
<dt> Port GUID</dt>
<dd> Identifies a port on a HCA, Switch, or Router (even a HCA often has multiple ports)</dd>
<dt> System GUID</dt>
<dd> Allows treating multiple GUIDs as one entity</dd>
<dt> LID (Local IDentifier)</dt>
<dd> 16-bit addresses, assigned by the Subnet Manager when picked up by the Subnet Manager.  Used for routing packets.  Not persistent through reboots.</dd>
</dl>
<h3><span class="mw-headline" id="NEED_ANOTHER_NAME">NEED ANOTHER NAME</span></h3>
<div class="noprint archwiki-template-message">
<p><a href="../File:Tango-edit-clear.png" class="image"><img alt="Tango-edit-clear.png" src="../File:Tango-edit-clear.png" width="48" height="48"></a><b>This article or section needs language, wiki syntax or style improvements.</b><a href="../File:Tango-edit-clear.png" class="image"><img alt="Tango-edit-clear.png" src="../File:Tango-edit-clear.png" width="48" height="48"></a></p>
<div>
<b>Reason:</b> Give the section a proper heading. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/index.php/Talk:InfiniBand">Talk:InfiniBand#</a>)</div>
</div>
<dl>
<dt> SM (Subnet Manager)</dt>
<dd> Actively manages an InfiniBand subnet.  Can be implemented as a software program on a computer connected to the InfiniBand network, built in to an InfiniBand switch, or as a specialized InfiniBand device.  Initializes and configures everything else on the subnet, including assigning LIDs (Local IDentifiers.)  Establishes traffic paths through the subnet.  Isolates faults.  Prevents unauthorized Subnet Managers.  You can have multiple switches all on one subnet, under one Subnet Manager.  You can have redundant Subnet Managers on one subnet, but only one can be active at a time.</dd>
</dl>
<dl>
<dt> MAD (MAnagement Datagram)</dt>
<dd> Standard message format for subnet manager to and from InfiniBand device communication, carried by a UD (Unreliable Datagram.)</dd>
<dt> UD (Unreliable Datagram)</dt>
<dd> </dd>
</dl>
<h3><span class="mw-headline" id="Software">Software</span></h3>
<div class="noprint archwiki-template-message">
<p><a href="../File:Tango-view-fullscreen.png" class="image"><img alt="Tango-view-fullscreen.png" src="../File:Tango-view-fullscreen.png" width="48" height="48"></a><b>This article or section needs expansion.</b><a href="../File:Tango-view-fullscreen.png" class="image"><img alt="Tango-view-fullscreen.png" src="../File:Tango-view-fullscreen.png" width="48" height="48"></a></p>
<div>
<b>Reason:</b> TODO. (Discuss in <a rel="nofollow" class="external text" href="https://wiki.archlinux.org/index.php/Talk:InfiniBand">Talk:InfiniBand#</a>)</div>
</div>
<h2><span class="mw-headline" id="Software_installation">Software installation</span></h2>
<p>This article makes many references to the InfiniBand AUR packages.  You can <a href="../en/Arch_User_Repository.html#Installing_packages" title="Arch User Repository">obtain and install AUR packages any way you wish</a>.
</p>
<h3><span class="mw-headline" id="Upgrade_firmware">Upgrade firmware</span></h3>
<p>Running the most recent firmware can give significant performance increases, and fix connectivity issues.
</p>
<div style="padding: 5px; margin: 0.50em 0; background-color: #FFDDDD; border: thin solid #DDBBBB; overflow: hidden;">
<strong> Warning: </strong>That being said, upgrade your firmware at your own risk!  Whatever device you're flashing new firmware onto, there is always some risk of bricking the device.</div>
<h4><span class="mw-headline" id="For_Mellanox">For Mellanox</span></h4>
<ul>
<li> Install <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/mstflint/">mstflint</a></span><sup><small>AUR</small></sup>, with prerequisites: <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/libibumad/">libibumad</a></span><sup><small>AUR</small></sup>; <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/libibmad/">libibmad</a></span><sup><small>AUR</small></sup>.</li>
<li> Determine your adapter's PCI device ID (in this example, "05:00.0" is the adapter's PCI device ID)</li>
</ul>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ lspci | grep Mellanox</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;"><b>05:00.0</b> InfiniBand: Mellanox Technologies MT25418 [ConnectX VPI PCIe 2.0 2.5GT/s - IB DDR / 10GigE] (rev a0)</pre>
<ul><li> Determine what firmware version your adapter has, and your adapter's PSID (more specific than just a model number - specific to a compatible set of revisions)</li></ul>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># mstflint -d &lt;adapter PCI device ID&gt; query</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">...
FW Version:      <b>2.7.1000</b>
...
PSID:            <b>MT_04A0110002</b></pre>
<ul>
<li> Check latest firmware version
<ul>
<li> Visit <a rel="nofollow" class="external text" href="http://www.mellanox.com/page/firmware_download">Mellanox's firmware download page</a>.  (This guide incorporates this link's "firmware burning instructions", using its mstflint option.)</li>
<li> Choose the category of device you have</li>
<li> Locate your device's PSID on their list, that mstflint gave you</li>
<li> Examine the Firmware Image filename to see if it's more recent than your adapter's FW Version.  (i.e. If Mellanox lists for your PSID a file fw-25408-2_9_1000-MHGH28-XTC_A1.bin.zip, that's a 2.9.1000 FW Version.)</li>
</ul>
</li>
<li> If there's a more recent version, download new firmware and burn it to your adapter</li>
</ul>
<pre>$ unzip &lt;<i>firmware .bin.zip file name</i>&gt;
# mstflint -d &lt;<i>adapter PCI device ID</i>&gt; -i &lt;<i>firmware .bin file name</i>&gt; burn
</pre>
<h4><span class="mw-headline" id="For_Intel.2FQLogic">For Intel/QLogic</span></h4>
<p>(Intel acquired QLogic's InfiniBand program) 
</p>
<p>... You figure it out, and update this wiki!  Maybe start at <a rel="nofollow" class="external free" href="http://driverdownloads.qlogic.com/QLogicDriverDownloads_UI/Defaultnewsearch.aspx">http://driverdownloads.qlogic.com/QLogicDriverDownloads_UI/Defaultnewsearch.aspx</a> or <a rel="nofollow" class="external free" href="https://downloadcenter.intel.com/">https://downloadcenter.intel.com/</a>
</p>
<h3><span class="mw-headline" id="Kernel_modules">Kernel modules</span></h3>
<p>Recent kernels have InfiniBand modules compiled in, and they just need to be loaded.
</p>
<ul><li> Install <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/rdma/">rdma</a></span><sup><small>AUR</small></sup>
<ul>
<li> Its <code>/usr/lib/udev/rules.d/98-rdma.rules</code> attempts loading hardware kernel modules cxgb*, ib_*, mlx*, iw_*, be2net, and usnic*.</li>
<li> Its <code>/usr/bin/rdma-init-kernel</code> (which is what <code>rdma.service</code> starts) loads kernel modules requested by <code>/etc/rdma.conf</code>.</li>
</ul>
</li></ul>
<table class="wikitable">
<caption> /etc/rdma.conf supports these options
</caption>
<tr>
<th> Option </th>
<th> If yes, loads category </th>
<th> of these kernel modules
</th>
</tr>
<tr>
<td> (Always) </td>
<td> Core  </td>
<td> ib_core, ib_mad, ib_sa, and ib_addr
</td>
</tr>
<tr>
<td> (Always) </td>
<td> Core user  </td>
<td> ib_umad, ib_uverbs, ib_ucm, and rdma_ucm
</td>
</tr>
<tr>
<td> (Always) </td>
<td> Core connection manager  </td>
<td> iw_cm, ib_cm, and rdma_cm
</td>
</tr>
<tr>
<td> IPOIB_LOAD=yes (default yes)* </td>
<td> Internet Protocol over InfiniBand </td>
<td> ib_ipoib
</td>
</tr>
<tr>
<td> RDS_LOAD=yes (default no) </td>
<td> Reliable Datagram Service  </td>
<td> rds, rds_tcp, and rds_rdma
</td>
</tr>
<tr>
<td> SRP_LOAD=yes (default no) </td>
<td> SCSI Remote Protocol initiator  </td>
<td> ib_srp
</td>
</tr>
<tr>
<td> SRPT_LOAD=yes (default no) </td>
<td> SCSI Remote Protocol target  </td>
<td> ib_srpt
</td>
</tr>
<tr>
<td> ISER_LOAD=yes (default no) </td>
<td> iSCSI over RDMA initiator  </td>
<td> ib_iser.
</td>
</tr>
<tr>
<td> ISERT_LOAD=yes (default no) </td>
<td> iSCSI over RDMA target  </td>
<td> ib_isert.
</td>
</tr>
<tr>
<td> (if lhca devices) </td>
<td> IBM pSeries Adapters (rare) </td>
<td> ib_ehca
</td>
</tr>
<tr>
<td> (if be2net module) </td>
<td> Emulex Adpaters (rare) </td>
<td> ocrdma
</td>
</tr>
</table>
<dl><dd>* ib_ipoib also loaded a dependency for <code>RDS_LOAD=yes</code>, or if <code>/etc/rdma.conf</code> doesn't exist</dd></dl>
<ul><li> <a href="../en/Systemd.html#Using_units" title="Start" class="mw-redirect">Start</a> and <a href="../en/Systemd.html#Using_units" title="Enable" class="mw-redirect">enable</a> <code>rdma.service</code>
</li></ul>
<div style="padding: 5px; margin: 0.50em 0; background-color: #DDDDFF; border: thin solid #BBBBDD; overflow: hidden;">
<strong> Note: </strong><a rel="nofollow" class="external text" href="https://bugzilla.redhat.com/show_bug.cgi?id=965829">Due to how the kernel stacks are handled</a>, changes to <code>/etc/rdma.conf</code> only take effect during boot, or upon a boot's first <a href="../en/Systemd.html#Using_units" title="Start" class="mw-redirect">start</a> of <code>rdma.service</code>.  Restarting <code>rdma.service</code> will have no effect.</div>
<h3><span class="mw-headline" id="Subnet_manager">Subnet manager</span></h3>
<p>Each InfiniBand network requires a subnet manager.  (It is also possible to set up a redundant subnet manager.)  Without one, your devices may show they have a link, but will never move past the state "Initializing" to "Active".  A subnet manager often (typically every 5 or 30 seconds) checks the InfiniBand for new adapters, and adds them to the network's routing tables.  If you have an InfiniBand switch with an embedded subnet manager, you can use that, or you can keep it disabled and use a software subnet manager instead.  Dedicated InfiniBand subnet manager devices also exist.
</p>
<h4><span class="mw-headline" id="For_a_software_subnet_manager.2C_use_opensm">For a software subnet manager, use opensm</span></h4>
<p>On one system:
</p>
<ul>
<li> <a href="#Kernel_modules">Install rdma for loading kernel modules</a>
</li>
<li> Install <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/opensm/">opensm</a></span><sup><small>AUR</small></sup>, with prerequisite <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/libibumad/">libibumad</a></span><sup><small>AUR</small></sup>.</li>
<li> <a href="../en/Systemd.html#Using_units" title="Start" class="mw-redirect">Start</a> and <a href="../en/Systemd.html#Using_units" title="Enable" class="mw-redirect">enable</a> <code>opensm.service</code>.</li>
</ul>
<p>All of your connected InfiniBand ports should now be in a (port) state of "Active", and a physical state of "LinkUp".  You can check this by running <a href="#ibstat_-_View_a_computer.27s_InfiniBand_GUIDs">ibstat</a> in <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/infiniband-diags/">infiniband-diags</a></span><sup><small>AUR</small></sup>:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ ibstat</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">... (look at the ports shown you expect to be connected)
State: Active
Physical state: LinkUp
...</pre>
<p>And/or by examining the <code>/sys</code> filesystem:
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ cat /sys/class/infiniband/<i>kernel_module</i>/ports/<i>port_number</i>/phys_state</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">5: LinkUp</pre>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ cat /sys/class/infiniband/<i>kernel_module</i>/ports/<i>port_number</i>/state</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">4: ACTIVE</pre>
<h3><span class="mw-headline" id="TCP.2FIP_over_InfiniBand_.28IPoIB.29">TCP/IP over InfiniBand (IPoIB)</span></h3>
<p>You can create a virtual Ethernet Adapter to be ran on an InfiniBand adapter.  This is intended so programs that are designed to work with TCP/IP but not InfiniBand, can (indirectly) use InfiniBand networks.  This is not intended to route internet traffic through your InfiniBand network.  (Unless your internet connection is faster than your Ethernet devices are... Which means you're working with <a href="https://en.wikipedia.org/wiki/Internet2" class="extiw" title="wikipedia:Internet2">Internet2</a>, <b>very</b> high performance supercomputers, clusters, or data centers, or you live in a handpicked area by <a rel="nofollow" class="external text" href="https://fiber.google.com/about/">Google Fiber</a> or <a rel="nofollow" class="external text" href="http://www.pcmag.com/article2/0,2817,2479953,00.asp">Comcast</a> offering a 2Gbps+ internet connection, which isn't available residentially anywhere as of mid 2015.)
</p>
<p>There is a performance hit for programs using InfiniBand via TCP/IP rather than natively.  Using IPoIB sends all traffic through the normal TCP stack, requires system calls, memory copies, and the network protocols are ran on the CPU rather than on the InfiniBand adapter.
</p>
<ul>
<li> <a href="#Kernel_modules">Install rdma for loading kernel modules</a>.</li>
<li> You should now have a network interface(s) (likely <code>ib<i>X</i></code> like <code>ib0</code>), that you <a href="../en/Network_configuration.html" title="Network configuration">can configure just like a traditional Ethernet adapter</a>.  If you only have one subnet with point-to-point connections (perhaps with switches) with no gateways, for:
<ul><li> <a href="../en/Systemd-networkd.html" title="Systemd-networkd">systemd-networkd</a>: (replacing the IP addresses as needed, to use a subnet that does not conflict with your existing private network IP addresses)</li></ul>
</li>
</ul>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/systemd/network/<i>interface</i>.network</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
[Match]
Name=<i>interface</i>

[Network]
Address=192.168.2.1/24</pre>
<dl><dd>
<dl><dd>
<a href="../en/Systemd.html#Using_units" title="Restart" class="mw-redirect">restart</a> (or <a href="../en/Systemd.html#Using_units" title="Start" class="mw-redirect">start</a> and <a href="../en/Systemd.html#Using_units" title="Enable" class="mw-redirect">enable</a>) <code>systemd-networkd.service</code>
</dd></dl>
<ul><li> <a href="../en/Network_configuration.html#systemd_service" title="Network configuration">static IP address via systemd service</a><sup>[<a href="../en/ArchWiki:Requests.html#Broken_section_links" title="ArchWiki:Requests">broken link</a>: invalid section]</sup>: (replacing the IP addresses as needed, to use a subnet that does not conflict with your existing private network IP addresses)</li></ul>
</dd></dl>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">/etc/conf.d/net-conf-<i>interface</i></pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
address=192.168.2.1
netmask=24
broadcast=192.168.2.255</pre>
<dl><dd><dl><dd>
<a href="../en/Systemd.html#Using_units" title="Start" class="mw-redirect">start</a> and <a href="../en/Systemd.html#Using_units" title="Enable" class="mw-redirect">enable</a> <code>network@<i>interface</i>.service</code>
</dd></dl></dd></dl>
<h4><span class="mw-headline" id="Connection_mode">Connection mode</span></h4>
<p>IPoIB can run in "datagram" (default), or "connected" mode.  Connected mode <a href="#Fine-tuning_MTU">allows you to set a higher MTU</a><sup>[<a href="../en/ArchWiki:Requests.html#Broken_section_links" title="ArchWiki:Requests">broken link</a>: invalid section]</sup>, but does increase TCP latency for short messages by about 5% more than datagram mode.
</p>
<p>To see the current mode used:
</p>
<pre>$ cat /sys/class/net/<i>interface</i>/mode
</pre>
<h4><span class="mw-headline" id="MTU">MTU</span></h4>
<p>In datagram mode, UD (Unreliable Datagram) transport is used, which typically forces the MTU to be 2044 bytes.  (Technically to the IB L2 MTU - 4 bytes for the IPoIB encapsulation header, which is usually 2044 bytes.)
</p>
<p>In connected mode, RC (Reliable Connected) transport is used, which allows a MTU up to the maximum IP packet size of 64K (65520 bytes is the exact maximum.)
</p>
<p>To see your MTU:
</p>
<pre>$ ip link show <i>interface</i>
</pre>
<h4><span class="mw-headline" id="Fine-tuning_connection_mode_and_MTU">Fine-tuning connection mode and MTU</span></h4>
<p>You only need <code>ipoibmodemtu</code> if you want to change the default connection mode and/or MTU.
</p>
<ul>
<li> <a href="#TCP.2FIP_over_InfiniBand_.28IPoIB.29">Install and set up TCP/IP over InfiniBand (IPoIB)</a>.</li>
<li> Install <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/ipoibmodemtu/">ipoibmodemtu</a></span><sup><small>AUR</small></sup>
</li>
<li> Configure <code>ipoibmodemtu</code> through <code>/etc/ipoibmodemtu.conf</code>, which contains instructions on how to do so.
<ul><li> It defaults to setting a single InfiniBand port <code>ib0</code> to <code>connected</code> mode and MTU <code>65520</code>.</li></ul>
</li>
<li> <a href="../en/Systemd.html#Using_units" title="Start" class="mw-redirect">Start</a> and <a href="../en/Systemd.html#Using_units" title="Enable" class="mw-redirect">enable</a> <code>ipoibmodemtu.service</code>
</li>
</ul>
<p>Different setups will see different results.  Some people see a gigantic (double+) speed increase by usign <code>connected</code> mode and MTU <code>65520</code>, and a few see about the same or even worse speeds.  Use <a href="#qperf_-_Measure_performance_over_RDMA_or_TCP.2FIP">qperf</a> and/or <a href="#iperf_-_Measure_performance_over_TCP.2FIP">iperf</a> to fine-tune your system.
</p>
<p>Using the <a href="#qperf_-_Measure_performance_over_RDMA_or_TCP.2FIP">qperf</a> examples given in this article, here are author's results on a SDR speed InfiniBand network (8 theoretical Gb/s) with various fine-tuning:
</p>
<table class="wikitable">
<tr>
<th> Mode </th>
<th> MTU </th>
<th> MB/s </th>
<th> us latency
</th>
</tr>
<tr>
<td> datagram </td>
<td> 2044 </td>
<td> 707 </td>
<td> 19.4
</td>
</tr>
<tr>
<td> connected </td>
<td> 2044 </td>
<td> 353 </td>
<td> 18.9
</td>
</tr>
<tr>
<td> connected </td>
<td> 65520 </td>
<td> 726 </td>
<td> 19.6
</td>
</tr>
</table>
<div style="padding: 5px; margin: 0.50em 0; background-color: #DDFFDD; border: thin solid #BBDDBB; overflow: hidden;">
<strong> Tip: </strong>It's usually best to have an entire subnet using the same connection and MTU settings.  Mixing and matching appears to work, but not optimally.</div>
<h3><span class="mw-headline" id="Remote_Data_Storage_over_InfiniBand">Remote Data Storage over InfiniBand</span></h3>
<p>You can share physical or virtual devices from a target (host/server) to an initiator (guest/client) system over an InfiniBand network, using iSCSI, iSCSI with iSER, or SRP.  These methods differ from traditional file sharing (i.e. <a href="../en/Samba.html" title="Samba">Samba</a> or <a href="../en/NFS.html" title="NFS">NFS</a>) because the initiator system views the shared device as its own block level device, rather than a traditionally mounted network shared folder.  i.e. <code>fdisk /dev/<i>block_device_id</i></code>, <code>mkfs.btrfs /dev/<i>block_device_id_with_partition_number</i></code>
</p>
<p>The disadvantage is only one system can use each shared device at a time; trying to mount a shared device on the target or another initiator system will fail.  (An initiator system can certainly run traditional file sharing on top.)
</p>
<p>The advantages are faster bandwidth, more control, and even having an initiator's root filesystem being physically located remotely (remote booting.)
</p>
<h4><span class="mw-headline" id="targetcli">targetcli</span></h4>
<p><code>targetcli</code> acts like a shell that presents its complex (and not worth creating by hand) <code>/etc/target/saveconfig.json</code> as a pseudo-filesystem.
</p>
<h5><span class="mw-headline" id="Installing_and_using">Installing and using</span></h5>
<p>On the target system:
</p>
<ul>
<li> Install <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/targetcli-fb/">targetcli-fb</a></span><sup><small>AUR</small></sup> with prerequisites: <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/python-configshell-fb/">python-configshell-fb</a></span><sup><small>AUR</small></sup>; and <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/python-rtslib-fb/">python-rtslib-fb</a></span><sup><small>AUR</small></sup>.</li>
<li> <a href="../en/Systemd.html#Using_units" title="Start" class="mw-redirect">Start</a> and <a href="../en/Systemd.html#Using_units" title="Enable" class="mw-redirect">enable</a> <code>target.service</code>
</li>
</ul>
<p>In <code>targetcli</code>:
</p>
<ul>
<li> In any pseudo-directory, you can run <code>help</code> to see the commands available <i>in that pseudo-directory</i>.  Or, <code>help <i>command</i></code> (like <code>help create</code>) for more detailed help.</li>
<li> Tab-completion is also available for many commands.</li>
<li> Run <code>ls</code> to see the entire pseudo-filesystem at and below the current pseudo-directory.</li>
</ul>
<h5><span class="mw-headline" id="Create_backstores">Create backstores</span></h5>
<p>In <code>targetcli</code>, setup a backstore for each device or virtual device to share:
</p>
<ul>
<li> To share an actual block device, run: <code>cd /backstores/block</code>; and <code>create <i>name</i> <i>dev</i></code>.</li>
<li> To share a file as a virtual block device, run: <code>cd /backstores/fileio</code>; and <code>create <i>name</i> <i>file</i></code>.</li>
<li> To share a physical SCSI device as a pass-through, run: <code>cd /backstores/pscsi</code>; and <code>create <i>name</i> <i>dev</i></code>.</li>
<li> To share a RAM disk, run: <code>cd /backstores/ramdisk</code>; and <code>create <i>name</i> <i>size</i></code>.</li>
<li> Where <i>name</i> is for the backstore's name.</li>
<li> Where <i>dev</i> is the block device to share (i.e. /dev/sda, /dev/sda4, /dev/disk/by-id/<i>x</i>, or a LVM logical volume /dev/vg0/lv1).</li>
<li> Where <i>file</i> is the file to share (i.e. <i>/path/to/file</i>).</li>
<li> Where <i>size</i> is the size of the RAM disk to create (i.e. 512MB, 20GB.)</li>
</ul>
<h4><span class="mw-headline" id="iSCSI">iSCSI</span></h4>
<p>iSCSI allows storage devices and virtual storage devices to be used over a network.  For InfiniBand networks, the storage can either work over IPoIB or iSER.
</p>
<p>There is a lot of overlap with the <a href="../en/ISCSI_Target.html" title="ISCSI Target">iSCSI Target</a>, <a href="../en/ISCSI_Initiator.html" title="ISCSI Initiator">iSCSI Initiator</a>, and <a href="../en/ISCSI_Boot.html" title="ISCSI Boot">iSCSI Boot</a> articles, but the necessities will be discussed since much needs to be customized for usage over InfiniBand.
</p>
<h5><span class="mw-headline" id="Over_IPoIB">Over IPoIB</span></h5>
<p>Perform the target system instructions first, which will direct you when to temporarily switch over to the initiator system instructions.
</p>
<ul><li> On the target and initiator systems, <a href="#TCP.2FIP_over_InfiniBand_.28IPoIB.29">install TCP/IP over InfiniBand</a>.</li></ul>
<ul><li> On the target system, for each device or virtual device you want to share, in <code>targetcli</code>:
<ul>
<li> <a href="#Create_backstores">Create a backstore</a>.</li>
<li> For each backstore, create an iqn (iSCSI Qualified Name) (the name other systems' configurations will see the storage as.)
<ul>
<li> Run: <code>cd /iscsi</code>; and <code>create</code>.  It will give you a <i>randomly_generated_target_name</i>, i.e. iqn.2003-01.org.linux-iscsi.hostname.x8664:sn.3d74b8d4020a.</li>
<li> Set up the tpg (Target Portal Group), automatically created in the last step as tpg1.
<ul>
<li> Create a lun (Logical Unit Number).
<ul><li> Run: <code>cd <i>randomly_generated_target_name</i>/tpg1/luns</code>; and <code>create <i>storage_object</i></code>.  Where <code><i>storage_object</i></code> is a full path to an existing storage object, i.e. /backstores/block/<i>name</i>.</li></ul>
</li>
<li> Create an acl (Access Control List).
<ul><li> Run: <code>cd ../acls</code>; and <code>create <i>wwn</i></code>.  Where <code><i>wwn</i></code> is the initiator system's iqn (iSCSI Qualified Name), aka its (World Wide Name).
<ul><li> Get the <code><i>wwn</i></code> by running on the initiator system, <b>not</b> this target system: (after installing on it <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://www.archlinux.org/packages/?name=open-iscsi">open-iscsi</a></span> or <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/open-iscsi-git/">open-iscsi-git</a></span><sup><small>AUR</small></sup>) <code>cat /etc/iscsi/initiatorname.iscsi</code>.</li></ul>
</li></ul>
</li>
</ul>
</li>
</ul>
</li>
<li> Save and exit by running: <code>cd /</code>; <code>saveconfig</code>; and <code>exit</code>.</li>
</ul>
</li></ul>
<ul><li> On the initiator system:
<ul>
<li> Install <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://www.archlinux.org/packages/?name=open-iscsi">open-iscsi</a></span>, or <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/open-iscsi-git/">open-iscsi-git</a></span><sup><small>AUR</small></sup>.</li>
<li> <a href="../en/Systemd.html#Using_units" title="Start" class="mw-redirect">Start</a> and <a href="../en/Systemd.html#Using_units" title="Enable" class="mw-redirect">enable</a> open-iscsi.service.</li>
<li> At this point, if you need this initiator system's iqn (iSCSI Qualified Name), aka its wwn (World Wide Name), for setting up the target system's <code>luns</code>, run: <code>cat /etc/iscsi/initiatorname.iscsi</code>.</li>
<li> Discover online targets.  Run <code>iscsiadm -m discovery -t sendtargets -p <i>portal</i></code>, where <i>portal</i> is an IP (v4 or v6) address or hostname.</li>
<li> Login to discovered targets.  Run <code>iscsiadm -m node -L all</code>.</li>
<li> View which block device ID was given to each target logged into.  Run <code>iscsiadm -m session -P 3 | grep Attached</code>.  The block device ID will be the last line in the tree for each target.  (<code>-P</code> is the print command, its option is the verbosity level, and only level 3 lists the block device IDs.)</li>
</ul>
</li></ul>
<h5><span class="mw-headline" id="Over_iSER">Over iSER</span></h5>
<p>iSER (iSCSI Extensions for RDMA) takes advantage of InfiniBand's RDMA protocols, rather than using TCP/IP.  It eliminates TCP/IP overhead, and provides higher bandwidth, zero copy time, lower latency, and lower CPU utilization.
</p>
<h6><span class="mw-headline" id="Bug_with_multiple_iSER_devices.2C_workarounds">Bug with multiple iSER devices, workarounds</span></h6>
<p>As of <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://www.archlinux.org/packages/?name=open-iscsi">open-iscsi</a></span> 2.0_873-7, if you try discovering multiple iSER devices, as described below, <code>iscsiadm</code> will give this error:
</p>
<pre>  iscsiadm: recv's end state machine bug?
  iscsiadm: Could not perform SendTargets discovery: iSCSI PDU timed out
</pre>
<p>The bug was fixed long ago, but the <a rel="nofollow" class="external text" href="https://github.com/open-iscsi/open-iscsi">open-iscsi developers</a> have not tagged a release since 2012, so <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://www.archlinux.org/packages/?name=open-iscsi">open-iscsi</a></span> 2.0_873-7 is using its source code from 2012.  So, your two workarounds are:
</p>
<ol>
<li> Use <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/open-iscsi-git/">open-iscsi-git</a></span><sup><small>AUR</small></sup>, to run the latest development branch source code.</li>
<li> Use the workaround described a few sections below.</li>
</ol>
<h6><span class="mw-headline" id="Configuring_iSER_devices">Configuring iSER devices</span></h6>
<p>You can use these instructions if you're going to use a single iSER device, or if you're going to use multiple iSER devices and have installed <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/open-iscsi-git/">open-iscsi-git</a></span><sup><small>AUR</small></sup>.  If you're going to use multiple iSER devices and are using <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://www.archlinux.org/packages/?name=open-iscsi">open-iscsi</a></span> to run a tagged release version rather than the developmental branch source code, you need to use the workaround described in the section below.
</p>
<p>Follow the <a href="#Over_IPoIB">iSCSI Over IPoIB</a> instructions, with the following changes:
</p>
<ul>
<li> If you wish, instead of <a href="#TCP.2FIP_over_InfiniBand_.28IPoIB.29">installing IPoIB</a>, you can just <a href="#Kernel_modules">install RDMA for loading kernel modules</a>.</li>
<li> On the target system, after everything else is setup, while still in <code>targetcli</code>, enable iSER on the target:
<ul>
<li> Run <code>cd /iscsi/<i>iqn</i>/tpg1/portals/0.0.0.0:3260</code> for each <i>iqn</i> you want to have use iSER rather than IPoIB.
<ul><li> Where <i>iqn</i> is the randomly generated target name, i.e. iqn.2003-01.org.linux-iscsi.hostname.x8664:sn.3d74b8d4020a.</li></ul>
</li>
<li> Run <code>enable_iser true</code>.</li>
<li> Save and exit by running: <code>cd /</code>; <code>saveconfig</code>; and <code>exit</code>.</li>
</ul>
</li>
<li> On the initiator system, when running <code>iscsiadm</code> to discover online targets and login to them, use the additional argument <code>-I iser</code>.</li>
</ul>
<h6><span class="mw-headline" id="Workaround_for_multiple_iSER_devices_on_open-iscsi_2.0_873-7">Workaround for multiple iSER devices on open-iscsi 2.0_873-7</span></h6>
<p>The bug only affects discovering multiple iSER devices.  Once they're discovered, you can login to them, and fully use them.  So as a workaround, you can discover the targets using IPoIB, change the target to iSER, make the 3 changes (filename, and two setting values) that <code>open-iscsi -m discovery</code> would make using iSER on the initiator, and proceed as normal.
</p>
<ul>
<li> On the target system, follow the <a href="#Over_IPoIB">iSCSI Over IPoIB</a> instructions, <b>without</b> the changes for <a href="#Configuring_iSER_devices">Configuring iSER devices</a>.</li>
<li> On the initiator system, follow the <a href="#Over_IPoIB">iSCSI Over IPoIB</a> instructions, <b>up to and including</b> discovering online targets, <b>without</b> the changes for <a href="#Configuring_iSER_devices">Configuring iSER devices</a>.  Then:
<ul>
<li> Run <code>systemctl stop open-iscsi</code>.</li>
<li> Rename each <code>/etc/iscsi/nodes/<i>iqn</i>/<i>ip-port</i>/default</code> file to <code>iser</code>, and edit each of these files.
<ul>
<li> Where <i>iqn</i> is the randomly generated target name in targetcli, i.e. iqn.2003-01.org.linux-iscsi.hostname.x8664:sn.3d74b8d4020a.</li>
<li> Where <i>ip-port-etc</i> is a directory in the form "192.168.2.1,3260,1".</li>
<li> Change <code>iface.iscsi_ifacename = default</code> to <code>iface.iscsi_ifacename = iser</code>.</li>
<li> Change <code>iface.transport_name = tcp</code> to <code>iface.transport_name = iser</code>.</li>
</ul>
</li>
</ul>
</li>
<li> On the target system, enable iSER by following the <a href="#Configuring_iSER_devices">Configuring iSER devices</a> instructions for the target system.</li>
<li> On the initiator system:
<ul>
<li> Run <code>systemctl start open-iscsi</code>.</li>
<li> When logging in to discovered targets, run <code>iscsiadm -m node -L all -I iser</code>.</li>
</ul>
</li>
</ul>
<h4><span class="mw-headline" id="SRP">SRP</span></h4>
<h2><span class="mw-headline" id="InfiniBand_programs_for_diagnosing_and_benchmarking">InfiniBand programs for diagnosing and benchmarking</span></h2>
<h3><span class="mw-headline" id="ibstat_-_View_a_computer.27s_InfiniBand_GUIDs">ibstat - View a computer's InfiniBand GUIDs</span></h3>
<p>ibstat will show you detailed information about each InfiniBand adapter in the computer it is ran on, including: model number; number of ports; firmware and hardware version; node, system image, and port GUIDs; and port state, physical state, rate, base lid, lmc, SM lid, capability mask, and link layer.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ ibstat</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">CA 'mlx4_0'
        CA type: MT25418
        Number of ports: 2
        Firmware version: 2.9.1000
        Hardware version: a0
        Node GUID: 0x0002c90300002f78
        System image GUID: 0x0002c90300002f7b
        Port 1:
                State: Active
                Physical state: LinkUp
                Rate: 20
                Base lid: 3
                LMC: 0
                SM lid: 3
                Capability mask: 0x0251086a
                Port GUID: 0x0002c90300002f79
                Link layer: InfiniBand
        Port 2:
                State: Down
                Physical state: Polling
                Rate: 10
                Base lid: 0
                LMC: 0
                SM lid: 0
                Capability mask: 0x02510868
                Port GUID: 0x0002c90300002f7a
                Link layer: InfiniBand</pre>
<p>This example shows a Mellanox Technologies (MT) adapter.  Its PCI Device ID is reported (25418), rather than the model number of part number.  It shows a state of "Active", which means is it properly connected to a subnet manager.  It shows a physical state of "LinkUp", which means it has an electrical connection via cable, but is not necessarily properly connected to a subnet manager.  It shows a total rate of 20 Gb/s (which for this card is from a 5.0 Gb/s signaling rate and 4 virtual lanes.)  It shows the subnet manager assigned the port a lid of 3.
</p>
<h3><span class="mw-headline" id="ibhosts_-_View_all_hosts_on_InfiniBand_network">ibhosts - View all hosts on InfiniBand network</span></h3>
<p>ibhosts will show you the Node GUIDs, number of ports, and device names, for each host on the InfiniBand network.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># ibhosts</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
Ca      : 0x0002c90300002778 ports 2 "MT25408 ConnectX Mellanox Technologies"
Ca      : 0x0002c90300002f78 ports 2 "hostname mlx4_0"</pre>
<h3><span class="mw-headline" id="ibswitches_-_View_all_switches_on_InfiniBand_network">ibswitches - View all switches on InfiniBand network</span></h3>
<p>ibswitches will show you the Node GUIDs, number of ports, and device names, for each switch on the InfiniBand network.  If you are running with direct connections only, it will show nothing.
</p>
<pre># ibswitches
</pre>
<h3><span class="mw-headline" id="iblinkinfo_-_View_link_information_on_InfiniBand_network">iblinkinfo - View link information on InfiniBand network</span></h3>
<p>iblinkinfo will show you the device names, Port GUIDs, number of virtual lanes, <a href="#Signal_transfer_rates">signal transfer rates</a>, state, physical state, and what it is connected to.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># iblinkinfo</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
CA: MT25408 ConnectX Mellanox Technologies:
      0x0002c90300002779      4    1[  ] ==( 4X           5.0 Gbps Active/  LinkUp)==&gt;       3    1[  ] "kvm mlx4_0" ( )
CA: hostname mlx4_0:
      0x0002c90300002f79      3    1[  ] ==( 4X           5.0 Gbps Active/  LinkUp)==&gt;       4    1[  ] "MT25408 ConnectX Mellanox Technologies" ( )</pre>
<p>This example shows two adapters directly connected with out a switch, using a 5.0 Gb/s <a href="#Signal_transfer_rates">signal transfer rate</a>, and 4 virtual lanes (4X).  
</p>
<h3><span class="mw-headline" id="ibping_-_Ping_another_InfiniBand_device">ibping - Ping another InfiniBand device</span></h3>
<p>ibping will attempt pinging another InfiniBand GUID.  ibping must be ran in server mode on one computer, and in client mode on another.
</p>
<p>ibping must be ran in server mode on one computer.
</p>
<pre># ibping -S
</pre>
<p>And in client mode on another.  It is pinging a specific port, so it cannot take a CA name, or a Node or System GUID.  It requires <code>-G</code> with a Port GUID, or <code>-L</code> with a Lid.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># ibping -G 0x0002c90300002779
-or-
# ibping -L 1</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
Pong from hostname.(none) (Lid 1): time 0.053 ms
Pong from hostname.(none) (Lid 1): time 0.074 ms
^C
--- hostname.(none) (Lid 4) ibping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1630 ms
rtt min/avg/max = 0.053/0.063/0.074 ms</pre>
<p>If you're running IPoIB, you can use regular <code>ping</code> which pings through the TCP/IP stack.  ibping uses InfiniBand interfaces, and does not use the TCP/IP stack.
</p>
<h3><span class="mw-headline" id="ibdiagnet_-_Show_diagnostic_information_for_entire_subnet">ibdiagnet - Show diagnostic information for entire subnet</span></h3>
<p>ibdiagnet will show you potential problems on your subnet.  You can run it without options.  <code>-lw &lt;1x|4x|12x&gt;</code> specifies the expected link width (number of virtual lanes) for your computer's adapter, so it can check if it is running as intended.  <code>-ls &lt;2.5|5|10&gt;</code> specifies the expected link speed (signaling rate) for your computer's adapter, so it can check if it is running as intended, but it does not yet support options faster than 10 for FDR+ devices.  <code>-c &lt;count&gt;</code> overrides the default number of packets to be sent of 10.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># ibdiagnet -lw 4x -ls 5 -c 1000</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
Loading IBDIAGNET from: /usr/lib/ibdiagnet1.5.7
-W- Topology file is not specified.
    Reports regarding cluster links will use direct routes.
Loading IBDM from: /usr/lib/ibdm1.5.7
-I- Using port 1 as the local port.
-I- Discovering ... 2 nodes (0 Switches &amp; 2 CA-s) discovered.


-I---------------------------------------------------
-I- Bad Guids/LIDs Info
-I---------------------------------------------------
-I- No bad Guids were found

-I---------------------------------------------------
-I- Links With Logical State = INIT
-I---------------------------------------------------
-I- No bad Links (with logical state = INIT) were found

-I---------------------------------------------------
-I- General Device Info
-I---------------------------------------------------

-I---------------------------------------------------
-I- PM Counters Info
-I---------------------------------------------------
-I- No illegal PM counters values were found

-I---------------------------------------------------
-I- Links With links width != 4x (as set by -lw option)
-I---------------------------------------------------
-I- No unmatched Links (with width != 4x) were found

-I---------------------------------------------------
-I- Links With links speed != 5 (as set by -ls option)
-I---------------------------------------------------
-I- No unmatched Links (with speed != 5) were found

-I---------------------------------------------------
-I- Fabric Partitions Report (see ibdiagnet.pkey for a full hosts list)
-I---------------------------------------------------
-I-    PKey:0x7fff Hosts:2 full:2 limited:0

-I---------------------------------------------------
-I- IPoIB Subnets Check
-I---------------------------------------------------
-I- Subnet: IPv4 PKey:0x7fff QKey:0x00000b1b MTU:2048Byte rate:10Gbps SL:0x00
-W- Suboptimal rate for group. Lowest member rate:20Gbps &gt; group-rate:10Gbps

-I---------------------------------------------------
-I- Bad Links Info
-I- No bad link were found
-I---------------------------------------------------
----------------------------------------------------------------
-I- Stages Status Report:
    STAGE                                    Errors Warnings
    Bad GUIDs/LIDs Check                     0      0     
    Link State Active Check                  0      0     
    General Devices Info Report              0      0     
    Performance Counters Report              0      0     
    Specific Link Width Check                0      0     
    Specific Link Speed Check                0      0     
    Partitions Check                         0      0     
    IPoIB Subnets Check                      0      1     

Please see /tmp/ibdiagnet.log for complete log
----------------------------------------------------------------
 
-I- Done. Run time was 0 seconds.</pre>
<h3><span class="mw-headline" id="qperf_-_Measure_performance_over_RDMA_or_TCP.2FIP">qperf - Measure performance over RDMA or TCP/IP</span></h3>
<p>qperf can measure bandwidth and latency over RDMA (SDP, UDP, UD, and UC) or TCP/IP (including IPoIB)
</p>
<p>qperf must be ran in server mode on one computer.
</p>
<pre>$ qperf
</pre>
<p>And in client mode on another.  SERVERNODE can be a hostname, or for IPoIB a TCP/IP address.  There are many tests.  Some of the most useful are below.
</p>
<pre>$ qperf SERVERNODE [OPTIONS] TESTS
</pre>
<h4><span class="mw-headline" id="TCP.2FIP_over_IPoIB">TCP/IP over IPoIB</span></h4>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ qperf 192.168.2.2 tcp_bw tcp_lat</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
tcp_bw:
    bw  =  701 MB/sec
tcp_lat:
    latency  =  19.8 us</pre>
<h3><span class="mw-headline" id="iperf_-_Measure_performance_over_TCP.2FIP">iperf - Measure performance over TCP/IP</span></h3>
<p>iperf is not an InfiniBand aware program, and is meant to test over TCP/IP or UDP.  Even though <a href="#qperf_-_Measure_performance_over_TCP.2FIP_or_RDMA">#qperf - Measure performance over TCP/IP or RDMA</a><sup>[<a href="../en/ArchWiki:Requests.html#Broken_section_links" title="ArchWiki:Requests">broken link</a>: invalid section]</sup> can test your InfiniBand TCP/IP performace using IPoIB, iperf is still another program you can use.
</p>
<p>iperf must be ran in server mode on one computer.
</p>
<pre>$ iperf3 -s
</pre>
<p>And in client mode on another.
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ iperf3 -c 192.168.2.2</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
[  4] local 192.168.2.1 port 20139 connected to 192.168.2.2 port 5201
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-1.00   sec   639 MBytes  5.36 Gbits/sec                  
...
[  4]   9.00-10.00  sec   638 MBytes  5.35 Gbits/sec                  
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth
[  4]   0.00-10.00  sec  6.23 GBytes  5.35 Gbits/sec                  sender
[  4]   0.00-10.00  sec  6.23 GBytes  5.35 Gbits/sec                  receiver

iperf Done.</pre>
<p>iperf shows Transfer in base 10 GB's, and Bandwidth in base 2 GB's.  So, this example shows 6.23GB (base 10) in 10 seconds. That's 6.69GB (base 2) in 10 seconds. (6.23 * 2^30 / 10^9) That's 5.35 Gb/s (base 2), as shown by iperf. (6.23 * 2^30 / 10^9 * 8 / 10) That's 685 MB/s (base 2), which is roughly the speed that qperf reported. (6.23 * 2^30 / 10^9 * 8 / 10 * 1024 / 8)
</p>
<h2><span class="mw-headline" id="Common_problems_.2F_FAQ">Common problems / FAQ</span></h2>
<h3><span class="mw-headline" id="Connection_problems">Connection problems</span></h3>
<h4><span class="mw-headline" id="Link.2C_physical_state.2C_and_port_state">Link, physical state, and port state</span></h4>
<ul><li> See if the InfiniBand hardware modules are recognized by the system.</li></ul>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ dmesg | egrep -i "Mellanox|InfiniBand|QLogic|Voltaire" # If you have an Intel adapter, you'll have to use Intel here and look through a few lines if you have other Intel hardware</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
[    6.287556] mlx4_core: Mellanox ConnectX core driver v2.2-1 (Feb, 2014)
[    8.686257] &lt;mlx4_ib&gt; mlx4_ib_add: mlx4_ib: Mellanox ConnectX InfiniBand driver v2.2-1 (Feb 2014)</pre>
<p>-and/or-
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ ls -l /sys/class/infiniband</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
mlx4_0 -&gt; ../../devices/pci0000:00/0000:00:03.0/0000:05:00.0/infiniband/mlx4_0</pre>
<p>If nothing is shown, your kernel isn't recognizing your adapter.  This example shows approximately what you will see if you have a Mellanox ConnectX adapter, which uses the mlx4_0 kernel module.
</p>
<ul><li> Check the port and physical states.  Either run <a href="#ibstat_-_View_a_computer.27s_InfiniBand_GUIDs">ibstat</a>, or examine the /sys filesystem.</li></ul>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ ibstat</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
(look at the port shown you expect to be connected)</pre>
<p>-and/or-
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ cat /sys/class/infiniband/&lt;kernel module&gt;/ports/&lt;port number&gt;/phys_state</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
 5: LinkUp</pre>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ cat /sys/class/infiniband/&lt;kernel module&gt;/ports/&lt;port number&gt;/state</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
 4: ACTIVE</pre>
<p>The physical state should be "LinkUp".  If it isn't, your cable likely isn't plugged in, isn't connected to anything on the other end, or is defective.  The (port) state should be "Active".  If it's "Initializing" or "INIT", your <a href="#Subnet_manager">subnet manager</a> doesn't exist, isn't running, or hasn't added the port to the network's routing tables.
</p>
<ul><li> Can you successfully <a href="#ibping_-_Ping_another_InfiniBand_device">ibping</a> which uses InfiniBand directly, rather than IPoIB?  Can you successfully <code>ping</code>, if you are running IPoIB?</li></ul>
<ul><li> Consider <a href="#Upgrade_firmware">upgrading firmware</a>.</li></ul>
<h4><span class="mw-headline" id="getaddrinfo_failed:_Name_or_service_not_known">getaddrinfo failed: Name or service not known</span></h4>
<ul><li> Run <a href="#ibhosts_-_View_all_hosts_on_InfiniBand_network">ibhosts</a> to see the CA names at the end of each line in quotes.</li></ul>
<h3><span class="mw-headline" id="Speed_problems">Speed problems</span></h3>
<ul><li> Start by double-checking your expectations.</li></ul>
<p>How have you determined you have a speed problem?  Are you using <a href="#qperf_-_Measure_performance_over_RDMA_or_TCP.2FIP">qperf</a> or <a href="#iperf_-_Measure_performance_over_TCP.2FIP">iperf</a>, which both transmit data to and from memory rather than hard drives.  Or, are you benchmarking actual file transfers, which relies on your hard drives?  Unless you're running RAID to boost speed, even with the fastest SSD's available in mid 2015, a single hard drive (or sometimes even multiple ones) will be bottlenecking your InfiniBand transfer speeds.  Are you using RDMA or TCP/IP via IPoIB?  If so, <a href="#TCP.2FIP_over_InfiniBand_.28IPoIB.29">there is a performance hit</a> for using IPoIB instead of RDMA.
</p>
<ul><li> Check your link speeds.  Run <a href="#ibstat_-_View_a_computer.27s_InfiniBand_GUIDs">ibstat</a>, <a href="#iblinkinfo_-_View_link_information_on_InfiniBand_network">iblinkinfo</a>, or examine the /sys filesystem.</li></ul>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ ibstat</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
(look at the Rate shown on the port you are using.)</pre>
<p>-and/or-
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;"># iblinkinfo</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
(look at the middle part formatted like "4X     5.0 Gbps")</pre>
<p>-and/or-
</p>
<pre style="margin-bottom: 0; border-bottom:none; padding-bottom:0.8em;">$ cat /sys/class/infiniband/&lt;kernel module&gt;/ports/&lt;port number&gt;/rate</pre>
<pre style="margin-top: 0; border-top-style:dashed; padding-top: 0.8em;">
20 Gb/sec (4X DDR)</pre>
<p>Does this match your expected <a href="#Bandwidth">bandwidth and number of virtual lanes</a>?
</p>
<ul><li> Check diagnostic information for entire subnet.  Run <a href="#ibdiagnet_-_Show_diagnostic_information_for_entire_subnet">#ibdiagnet - Show diagnostic information for entire subnet</a>.  Make sure to use <code>-ls </code> with <a href="#Bandwidth">the proper signaling rate, which is likely the advertised speed of your card divided by 4</a>.</li></ul>
<pre># ibdiagnet -lw &lt;expected number of virtual lanes -ls &lt;expected signaling rate&gt; -c 1000
</pre>
<ul><li> Consider <a href="#Upgrade_firmware">upgrading firmware</a>.</li></ul>
<h2><span class="mw-headline" id="Network_segmentation">Network segmentation</span></h2>
<p>An InfiniBand subnet can be partitioned for different customers or applications, giving security and quality of service guarantees.  Each partition is identified by a PKEY (Partition Key.)
</p>
<h2><span class="mw-headline" id="How_can_I_use_libsdp_for_SDP_.28Sockets_Direct_Protocol.29.3F_.3D">How can I use libsdp for SDP (Sockets Direct Protocol)? =</span></h2>
<p>Use <span class="plainlinks archwiki-template-pkg"><a rel="nofollow" class="external text" href="https://aur.archlinux.org/packages/librdmacm/">librdmacm</a></span><sup><small>AUR</small></sup> instead.  (When it started, it was called rsockets.)
</p>
<p>librdmacm (and formerly libsdp) use <code>LD_PRELOAD</code> to intercept non-Infiniband programs' socket calls, and transparently (to the program) send them over RDMA over InfiniBand.  That is, it can dramatically speed up programs built for TCP/IP, more than you can achieve by using them with IPoIB.  It avoids the need to change a program's source code to work with InfiniBand, and can even be used on programs without the user having the source code.  It does not work on programs that statically linked in socket libraries.
</p>
<p>libsdp was deprecated.  The ib_sdp kernel module is no longer maintained or distributed.
</p>
</div>
<div id="catlinks" class="catlinks">
<div id="mw-normal-catlinks" class="mw-normal-catlinks">
<a href="../Special:Categories.html" title="Special:Categories">Category</a>: <ul><li><a href="../en/Category:Networking.html" title="Category:Networking">Networking</a></li></ul>
</div>
<div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul>
<li><a href="../en/Category:Pages_or_sections_flagged_with_Template:Style.html" title="Category:Pages or sections flagged with Template:Style">Pages or sections flagged with Template:Style</a></li>
<li><a href="../en/Category:Pages_or_sections_flagged_with_Template:Expansion.html" title="Category:Pages or sections flagged with Template:Expansion">Pages or sections flagged with Template:Expansion</a></li>
<li><a href="../en/Category:Pages_with_broken_section_links.html" title="Category:Pages with broken section links">Pages with broken section links</a></li>
</ul>
</div>
</div>					<div class="visualClear"></div>
				</div>
			</div>
		</div>
		<div class="visualClear"></div>
					<div id="footer" role="contentinfo">
Extracted from <a href="https://wiki.archlinux.org"> ArchWiki </a> and licensed under <a href="http://www.gnu.org/copyleft/fdl.html"> GDL >= 1.3</a>
		</div>
		</div>
		</body>
</html>
